{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary libaries\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting MNIST Data...\n",
      "MNIST Data downloaded!\n"
     ]
    }
   ],
   "source": [
    "#Get MNIST Dataset\n",
    "print('Getting MNIST Data...')\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "print('MNIST Data downloaded!')\n",
    "\n",
    "images = mnist.data \n",
    "labels = mnist.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the images \n",
    "images = normalize(images, norm='l2') #You can use l1 norm too\n",
    "\n",
    "#Split the data into training set and test set\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.25,\n",
    "                                                                        random_state=17)\n",
    "\n",
    "#Setup the neural network that we want to train on, here we take 5 hidden layers with 100 nodes each\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100), max_iter=20, solver='adam', learning_rate_init=0.001,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Training started...\n",
      "Iteration 1, loss = 0.67745050\n",
      "Iteration 2, loss = 0.21889981\n",
      "Iteration 3, loss = 0.15387370\n",
      "Iteration 4, loss = 0.12107897\n",
      "Iteration 5, loss = 0.10066477\n",
      "Iteration 6, loss = 0.08795820\n",
      "Iteration 7, loss = 0.07282181\n",
      "Iteration 8, loss = 0.06488678\n",
      "Iteration 9, loss = 0.05682668\n",
      "Iteration 10, loss = 0.04848742\n",
      "Iteration 11, loss = 0.04388695\n",
      "Iteration 12, loss = 0.03899960\n",
      "Iteration 13, loss = 0.03380027\n",
      "Iteration 14, loss = 0.02946361\n",
      "Iteration 15, loss = 0.03056661\n",
      "Iteration 16, loss = 0.02303612\n",
      "Iteration 17, loss = 0.02016070\n",
      "Iteration 18, loss = 0.01726935\n",
      "Iteration 19, loss = 0.01651713\n",
      "Iteration 20, loss = 0.01407573\n",
      "NN Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ratan/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Performance: 0.973429\n"
     ]
    }
   ],
   "source": [
    "#Start training the network \n",
    "print('NN Training started...')\n",
    "nn.fit(images_train, labels_train)\n",
    "print('NN Training completed!')\n",
    "\n",
    "#Evaluate the performance of the neural network on test data \n",
    "print('Network Performance: %f' % nn.score(images_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
